{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6660c21-9b34-4416-88b8-6267a71d0692",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-8f076917e1ca>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8f076917e1ca>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from ../sapsam import parser, constants  #, detector\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sapsam import parser, constants  #, detector\n",
    "\n",
    "import filter_JSON_for_event_labels\n",
    "\n",
    "csv_paths = parser.get_csv_paths()\n",
    "\n",
    "# df_raw=pd.read_csv(os.getcwd()+'/models/0.csv', sep=\",\")\n",
    "csv_path = csv_paths[0]\n",
    "print(csv_path.name)\n",
    "df_raw = pd.read_csv(csv_path, nrows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc5b336-5b69-4ad2-88a5-dcea53a7ba93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_JSON_for_event_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-829a045b1586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_JSON_for_event_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_event_labels_to_DF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_JSON_for_event_labels' is not defined"
     ]
    }
   ],
   "source": [
    "df = filter_JSON_for_event_labels.add_event_labels_to_DF(df_raw)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4b72f-e792-4f7c-bb62-a5243eb2191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Revision ID', 'Organization ID', 'Datetime', 'Model JSON', 'Description', 'Type', 'Namespace'], inplace=True)\n",
    "df.dropna(subset=['event_labels'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df109f7-9a4a-41db-959a-b26e2c043e9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Language Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d99f07-ec33-46dd-ac82-2de96dc1e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f40b00-d272-427e-ba7f-689358414b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_df_models_and_labels(df, sep_str=\" \"):\n",
    "    df_labels = df.drop(columns=\"category\", axis=1)\n",
    "    df_labels.reset_index(inplace=True)\n",
    "    df_labels.drop(columns=\"element_id\", axis=1, inplace=True)\n",
    "    df_labels.label = df_labels.label.apply(lambda x: str(x or ''))\n",
    "    df_labels.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    df_labels['label'] = df_labels.groupby(['model_id'])['label'].transform(lambda x: sep_str.join(x))\n",
    "    df_labels.drop_duplicates(ignore_index=True, inplace=True)\n",
    "    return df_labels.set_index(\"model_id\")\n",
    "\n",
    "\n",
    "def clean(label):\n",
    "    # handle some special cases\n",
    "    label = label.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "    # delete unnecessary whitespaces\n",
    "    label = label.strip()\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "\n",
    "class ModelLanguageDetector:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "        self.nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "    def _get_text_language(self, text):\n",
    "        doc = self.nlp(str(clean(text)))\n",
    "        detection = doc._.language\n",
    "        return detection['language']\n",
    "\n",
    "    def add_detected_natural_language_from_meta(self, df_meta):\n",
    "        df_meta['detected_natural_language'] = [self._get_text_language(name) for name in tqdm(df_meta.name)]\n",
    "\n",
    "    def get_detected_natural_language_from_bpmn_model(self, series_txt):\n",
    " #       df_labels = get_df_models_and_labels(df, \" \")\n",
    "        # df['detected_natural_language'] = [self._get_text_language(label) for label in tqdm(df['event_labels'])]\n",
    "        return series_txt.apply(self._get_text_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cb846-a299-44c5-a58b-883b65e3f449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ld = ModelLanguageDetector(0.8) # comment this line if you have already created the pkl file\n",
    "df['detected_natural_language'] = ld.get_detected_natural_language_from_bpmn_model(df['event_labels']) # comment this line if you have already created the pkl file\n",
    "# df.to_pickle(constants.DATA_INTERIM / \"all_languages.pkl\") # comment this line if you have already created the pkl file\n",
    "# df = pd.read_pickle(constants.DATA_INTERIM / \"bpmn_languages.pkl\") # uncomment this line if you have already created the pkl file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b93011-f2ae-4e56-bff5-7cab5c211fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected_natural_language'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c057222-573e-41ae-9834-cbedd3b47436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['detected_natural_language'].isin(['en','ca'])]\n",
    "## todo: check all english language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a734c03-fd19-458a-87f2-abd90c36a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69fb19-f386-4191-a379-8a115d3737c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
